{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ObeIwb_npgeZ"
   },
   "source": [
    "# Tutorial de Ciencia de Datos (CC408) 2024\n",
    "## Tutorial 11 - PCR, PLS y Modelos no lineales\n",
    "\n",
    "**Objetivo:**\n",
    "Que se familiaricen con métodos de regresión basados en reducción de la dimensionalidad (PCR & PLS) y modelos no lineales y semi-paramétricos\n",
    "\n",
    "Esta tutorial es una adaptación del `Lab` de *Linear Models and Regularization Methods* del libro \"Introduction to Statistical Learning with Applications in Python\" por Gareth James, Daniela Witten, Trevor Hastie, Robert Tibshirani y Jonathan Taylor. [Acá](https://islp.readthedocs.io/en/latest/labs/Ch06-varselect-lab.html) pueden encontrar más información"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métodos de Regresión basados en reducción de la dimensionalidad\n",
    "El objetivo es buscar *transformar* los $p$ predictores y estimar una regresión lineal (por MCO) de $Y$ en los predictores transformados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regresión por Componentes Principales (PCR, principal component regression)\n",
    "\n",
    "Para estimar por una regresión por componentes principales (PCR), primero, usamos `PCA` del modulo de [PCA() de Scikit-Learn](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html). \n",
    "Luego, usamos la funcion conocida de `LinearRegression()` para estimar el modelo.\n",
    "\n",
    "En este ejemplo, aplicamos PCR a los datos de [Hitters](https://islp.readthedocs.io/en/latest/datasets/Hitters.html) para predecir `Salary`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos los paquetes necesarios\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib.pyplot import subplots\n",
    "\n",
    "import sklearn.model_selection as skm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from functools import partial\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_decomposition import PLSRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Preparamos los datos y transformamos variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos los datos datos\n",
    "Hitters = pd.read_csv('Hitters.csv')\n",
    "print(Hitters.info())\n",
    "print('Dimensión de la base:', Hitters.shape, '\\n')\n",
    "#Vemos los missing values en Y\n",
    "print('\\nMissings en variable dependiente:', np.isnan(Hitters['Salary']).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizamos la estadistica descriptiva de la base\n",
    "Hitters.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminamos missings en la variable dependiente\n",
    "Hitters = Hitters.dropna() \n",
    "print('\\n Nueva dimensión de la base:', Hitters.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora preparamos nuestras variables com y transformamos las variables string (como *League*) en dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = Hitters.Salary\n",
    "# Creamos variables dummies para las variables string\n",
    "dummies = pd.get_dummies(Hitters[['League', 'Division', 'NewLeague']], drop_first=True)\n",
    "dummies\n",
    "\n",
    "# Eliminamos salarios (porque es nuestra y) y las columnas de strings\n",
    "X_ = Hitters.drop(['Salary', 'League', 'Division', 'NewLeague'], axis=1).astype('float64')\n",
    "X = pd.concat([X_, dummies[['League_N', 'Division_W', 'NewLeague_N']]], axis=1)\n",
    "X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividimos la base en observaciones para el entrenamiento y testeo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=100)\n",
    "\n",
    "# Revisamos cuantas observaciones quedaron para Test y cuantas para Entrenamiento.\n",
    "print(f'El conjunto de entrenamiento tiene {len(X_train)} observaciones.')\n",
    "print(f'El conjunto de test tiene {len(X_test)} observaciones.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iniciamos el Standard Scaler\n",
    "sc = StandardScaler()\n",
    "\n",
    "# Estandarizamos las observaciones de entrenamiento\n",
    "X_train_transformed = pd.DataFrame(sc.fit_transform(X_train), index=X_train.index, columns=X_train.columns)\n",
    "\n",
    "# Estandarizamos las observaciones de test\n",
    "X_test_transformed = pd.DataFrame(sc.transform(X_test), index=X_test.index, columns=X_test.columns)\n",
    "\n",
    "# Estadisticas luego de estandarizar\n",
    "X_train_transformed.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Regresion por Componentes principales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizamos la función [Pipeline()](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) de Sckit learn que permite en una forma clara, separar el paso de *transformar* los predictores y luego *estimar* el modelo de interés. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "linreg = LinearRegression()\n",
    "pipe = Pipeline([('pca', pca),\n",
    "                 ('linreg', linreg)])\n",
    "pipe.fit(X_train_transformed, y_train)\n",
    "print(f'Los coeficientes de la regresión usando dos componentes principales son:')\n",
    "print(pipe.named_steps['linreg'].coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos usar cross validation (CV) para buscar el número de componentes a utilizar en la regresión. Para eso, usaremos `skm.GridSearchCV`, donde el parámetro que varia es `n_components`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usamos 5-fold cross-validation\n",
    "K = 5\n",
    "kfold = skm.KFold(K,\n",
    "                  random_state=0,\n",
    "                  shuffle=True)\n",
    "\n",
    "# Definimos un rango de numerop de componentes principales\n",
    "param_grid = {'pca__n_components': range(1, 20)}\n",
    "\n",
    "\n",
    "grid = skm.GridSearchCV(pipe,\n",
    "                        param_grid,\n",
    "                        cv=kfold,\n",
    "                        scoring='neg_mean_squared_error')\n",
    "#Estimamos\n",
    "grid.fit(X_train_transformed, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora graficamos los resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcr_fig, ax = subplots(figsize=(6,6))\n",
    "n_comp = param_grid['pca__n_components']\n",
    "ax.errorbar(n_comp,\n",
    "            -grid.cv_results_['mean_test_score'],\n",
    "            grid.cv_results_['std_test_score'] / np.sqrt(K))\n",
    "ax.set_ylabel('CV MSE', fontsize=20)\n",
    "ax.set_xlabel('# componentes principales', fontsize=20)\n",
    "ax.set_xticks(n_comp[::2])\n",
    "ax.set_ylim([50000,250000]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con el atributo `explained_variance_ratio_` de `PCA` podemos ver el porcentaje de la varianza explicada en los predictores y en la respuesta usando distinto número de componentes principales. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.named_steps['pca'].explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto nos dice la cantidad de informacion sobre los predictores que es caputara usando $M$ componentes. Esto nos muestra que usar $M=1$ caputa un 38% de la varianza, mientras que $M=2$ captura 22%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Minimos Cuadrados Parciales (Partial Least Squares, PLS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minimos Cuadrados Parciales (PLS) se implementa con la funcion [PLSRegression()](https://scikit-learn.org/stable/modules/generated/sklearn.cross_decomposition.PLSRegression.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pls = PLSRegression(n_components=2, \n",
    "                    scale=True)\n",
    "pls.fit(X_train_transformed, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar al caso de PCR, usamos CV para elegir el numero de componentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'n_components':range(1, 20)}\n",
    "\n",
    "grid = skm.GridSearchCV(pls,\n",
    "                        param_grid,\n",
    "                        cv=kfold,\n",
    "                        scoring='neg_mean_squared_error')\n",
    "\n",
    "grid.fit(X_train_transformed, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De la misma forma, en un graficamos el MSE por CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pls_fig, ax = subplots(figsize=(6,6))\n",
    "n_comp = param_grid['n_components']\n",
    "ax.errorbar(n_comp,\n",
    "            -grid.cv_results_['mean_test_score'],\n",
    "            grid.cv_results_['std_test_score'] / np.sqrt(K))\n",
    "ax.set_ylabel('CV MSE', fontsize=20)\n",
    "ax.set_xlabel('# componentes', fontsize=20)\n",
    "ax.set_xticks(n_comp[::2])\n",
    "ax.set_ylim([50000,250000]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K4aM1xeLpgeg"
   },
   "source": [
    "# Modelos no lineales\n",
    "En el curso nos enfocamos principalmente en modelos lineales, por ser simples y por sus ventajas en términos de interpretabilidad e inferencia\n",
    "\n",
    "Sin embargo, el supuesto de linealidad es fuerte y a veces puede llevar a un menor poder predictivo. Ahora vamos a relajar el supuesto de linealidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 2156,
     "status": "ok",
     "timestamp": 1701294736284,
     "user": {
      "displayName": "Victoria Oubina de Castro",
      "userId": "00295192582253170882"
     },
     "user_tz": 180
    },
    "id": "oi4Dp6T8pgee"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib.pyplot import subplots\n",
    "#%matplotlib inline\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, r2_score, mean_absolute_error\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 298,
     "status": "ok",
     "timestamp": 1701294742642,
     "user": {
      "displayName": "Victoria Oubina de Castro",
      "userId": "00295192582253170882"
     },
     "user_tz": 180
    },
    "id": "PRAd4oJspgei",
    "outputId": "b8f14abd-5e6c-46ed-8078-de439a057912"
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('Wage.csv')\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 270,
     "status": "ok",
     "timestamp": 1701294744509,
     "user": {
      "displayName": "Victoria Oubina de Castro",
      "userId": "00295192582253170882"
     },
     "user_tz": 180
    },
    "id": "WRS2GA04Cwtr",
    "outputId": "76d0a93f-35aa-4836-e0fb-dde0a8a87459"
   },
   "outputs": [],
   "source": [
    "# Vamos a usar salario y edad\n",
    "X = dataset['age']\n",
    "y = dataset['wage']\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "executionInfo": {
     "elapsed": 1646,
     "status": "ok",
     "timestamp": 1701294747169,
     "user": {
      "displayName": "Victoria Oubina de Castro",
      "userId": "00295192582253170882"
     },
     "user_tz": 180
    },
    "id": "Ium1Fp_rCwtr",
    "outputId": "b2b16046-7c25-4ff5-ae4a-e332aaf03f83"
   },
   "outputs": [],
   "source": [
    "fig, ax = subplots(figsize=(8,4))\n",
    "ax.scatter(X, y, facecolor='gray', alpha=0.5)\n",
    "ax.set_xlabel('Age')\n",
    "ax.set_ylabel('Wage')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1701294748023,
     "user": {
      "displayName": "Victoria Oubina de Castro",
      "userId": "00295192582253170882"
     },
     "user_tz": 180
    },
    "id": "_iRalid3Cwtr"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regresión polinómica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 389,
     "status": "ok",
     "timestamp": 1701294748679,
     "user": {
      "displayName": "Victoria Oubina de Castro",
      "userId": "00295192582253170882"
     },
     "user_tz": 180
    },
    "id": "CFZYDoiDCwts",
    "outputId": "02a273f3-52b5-43e1-ae0e-afb2956c4ef3"
   },
   "outputs": [],
   "source": [
    "# Reshape para transformar x en un vector columna\n",
    "X_train_ = X_train.values.reshape((-1, 1)) # Convertir Series a NumPy array y reshape\n",
    "\n",
    "# Transformación polinomial\n",
    "model_pol = PolynomialFeatures(include_bias=True, degree=4)\n",
    "model_pol.fit(X_train_)\n",
    "X_train_t = model_pol.transform(X_train_)\n",
    "\n",
    "# Si en PolynomialFeatures ponemos include_bias=False, podemos agregar constante:\n",
    "#X_train_t = sm.add_constant(X_train_t)\n",
    "\n",
    "# Especificamos el modelo y ajustamos\n",
    "model_pol4 = sm.OLS(y_train, X_train_t)\n",
    "results = model_pol4.fit()\n",
    "\n",
    "print(results.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimamos el MSE de testeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1701294750877,
     "user": {
      "displayName": "Victoria Oubina de Castro",
      "userId": "00295192582253170882"
     },
     "user_tz": 180
    },
    "id": "zkr51kbHCwts",
    "outputId": "a9bf9d0f-8820-4b36-89d9-902073b187fd"
   },
   "outputs": [],
   "source": [
    "X_test_t = model_pol.fit_transform(X_test.values.reshape((-1, 1)))\n",
    "\n",
    "y_pred = results.predict(X_test_t)\n",
    "\n",
    "print('ECM:', mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "executionInfo": {
     "elapsed": 1159,
     "status": "ok",
     "timestamp": 1701294753893,
     "user": {
      "displayName": "Victoria Oubina de Castro",
      "userId": "00295192582253170882"
     },
     "user_tz": 180
    },
    "id": "GxHvruzDCwts",
    "outputId": "a538ba11-0692-4cbb-bbab-f1d4c8c5d965"
   },
   "outputs": [],
   "source": [
    "# Generamos otras X y sus predicciones para graficar\n",
    "X_seq = np.linspace(X.min(), X.max()).reshape(-1,1)\n",
    "X_seq_t = model_pol.fit_transform(X_seq)\n",
    "X_seq_pred = results.predict(X_seq_t)\n",
    "\n",
    "fig, ax = subplots(figsize=(8,4))\n",
    "ax.scatter(X, y, facecolor='gray', alpha=0.5)\n",
    "ax.plot(X_seq, X_seq_pred, label='Reg. polinómica grado 4', linewidth=3)\n",
    "ax.set_xlabel('Age')\n",
    "ax.set_ylabel('Wage')\n",
    "#ax.legend(title='Poly', fontsize=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1701294754683,
     "user": {
      "displayName": "Victoria Oubina de Castro",
      "userId": "00295192582253170882"
     },
     "user_tz": 180
    },
    "id": "hrYD3AvtCwtt",
    "outputId": "a12fd364-c8b8-4f0f-e704-f0947638f1c2"
   },
   "outputs": [],
   "source": [
    "results.predict(X_seq_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cBEKgfZQCwtt"
   },
   "source": [
    "Podemos elegir el grado del polinimio por CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ycUUieH5Cwtt"
   },
   "source": [
    "#### Step function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 272,
     "status": "ok",
     "timestamp": 1701294757481,
     "user": {
      "displayName": "Victoria Oubina de Castro",
      "userId": "00295192582253170882"
     },
     "user_tz": 180
    },
    "id": "a7piR-mGCwtt",
    "outputId": "c7b14e2b-4adc-4333-e3e8-8217d7464bf5"
   },
   "outputs": [],
   "source": [
    "# Hacemos a la edad (X) discreta en función de quintiles\n",
    "cut_X = pd.qcut(X, 4) #qcut con 4 quintiles\n",
    "cut_X\n",
    "# Nota pd.cut() permitiría hacer cortes no basados en quintiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 426,
     "status": "ok",
     "timestamp": 1701294759071,
     "user": {
      "displayName": "Victoria Oubina de Castro",
      "userId": "00295192582253170882"
     },
     "user_tz": 180
    },
    "id": "Kb7QqvP6Cwtu",
    "outputId": "ab971252-6f17-4dd6-8f6f-edd08e02f4cf"
   },
   "outputs": [],
   "source": [
    "# y creamos dummies para cada quintil\n",
    "q_X = pd.get_dummies(cut_X)\n",
    "q_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 259,
     "status": "ok",
     "timestamp": 1701294463354,
     "user": {
      "displayName": "Victoria Oubina de Castro",
      "userId": "00295192582253170882"
     },
     "user_tz": 180
    },
    "id": "anpAto9kCwtu",
    "outputId": "3ab207f7-cb14-4dec-c95d-7263b82c1cf3"
   },
   "outputs": [],
   "source": [
    "# Primera columna\n",
    "q_X.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 255,
     "status": "ok",
     "timestamp": 1701294769653,
     "user": {
      "displayName": "Victoria Oubina de Castro",
      "userId": "00295192582253170882"
     },
     "user_tz": 180
    },
    "id": "CVKKZ-bQpgel"
   },
   "outputs": [],
   "source": [
    "q_X_train, q_X_test, y_train, y_test = train_test_split(q_X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 261,
     "status": "ok",
     "timestamp": 1701294771418,
     "user": {
      "displayName": "Victoria Oubina de Castro",
      "userId": "00295192582253170882"
     },
     "user_tz": 180
    },
    "id": "EREeeUzSCwtu",
    "outputId": "5fcfbb53-3f57-444e-9e7c-dcd68bad5d95"
   },
   "outputs": [],
   "source": [
    "q_X_train_= sm.add_constant(q_X_train)\n",
    "\n",
    "# Especificamos el modelo y ajustamos\n",
    "q_model_pol4 = sm.OLS(y_train, q_X_train_.astype(float))\n",
    "q_results = q_model_pol4.fit()\n",
    "\n",
    "print(q_results.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "executionInfo": {
     "elapsed": 1265,
     "status": "ok",
     "timestamp": 1701294775735,
     "user": {
      "displayName": "Victoria Oubina de Castro",
      "userId": "00295192582253170882"
     },
     "user_tz": 180
    },
    "id": "5eqHh_atCwtu",
    "outputId": "9aabc024-9c65-4d84-c170-f57b585fac64"
   },
   "outputs": [],
   "source": [
    "q_pred =  q_results.predict(sm.add_constant(q_X_test)).values\n",
    "\n",
    "fig, ax = subplots(figsize=(10,6))\n",
    "ax.scatter(X, y, facecolor='gray', alpha=0.5)\n",
    "ax.plot(X_seq, results.predict(X_seq_t), label='Reg. polinómica grado 4', linewidth=4)\n",
    "ax.scatter(X_test.values.reshape(-1,1), q_pred, facecolor='red', alpha=0.9, label=\"Step function\")\n",
    "ax.set_xlabel('Age')\n",
    "ax.set_ylabel('Wage')\n",
    "ax.legend(title='', fontsize=12)\n",
    "ax.grid(True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1eM5mrq5pgem"
   },
   "source": [
    "#### Splines\n",
    "Idea: usar polinomios y step function\n",
    "\n",
    "Se determinan puntos de corte (knots) en X y se ajustan distintas regresiones para cada segmento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 244,
     "status": "ok",
     "timestamp": 1701296037468,
     "user": {
      "displayName": "Victoria Oubina de Castro",
      "userId": "00295192582253170882"
     },
     "user_tz": 180
    },
    "id": "QSwlEQ2HJM3q",
    "outputId": "e179306f-af95-425b-ebfe-c65797e5de92"
   },
   "outputs": [],
   "source": [
    "print('Min age:', min(dataset['age']), 'Max age:', max(dataset['age']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "executionInfo": {
     "elapsed": 1509,
     "status": "ok",
     "timestamp": 1701296274020,
     "user": {
      "displayName": "Victoria Oubina de Castro",
      "userId": "00295192582253170882"
     },
     "user_tz": 180
    },
    "id": "H1Tv5EMBCwtv",
    "outputId": "6515eb23-12b3-40f2-f118-8c61afa73d47"
   },
   "outputs": [],
   "source": [
    "from scipy.interpolate import BSpline\n",
    "\n",
    "# Definimos knots y grado del polinomio\n",
    "knots=[18, 24, 30, 36, 42, 48, 54, 60, 66, 72, 78]\n",
    "degree=3\n",
    "t = [min(dataset['age'])] + knots + [max(dataset['age'])]\n",
    "spl = BSpline(t, list(dataset['wage']), degree)\n",
    "\n",
    "# Grilla para evaluar spline\n",
    "x_smooth = np.linspace(min(dataset['age']), max(dataset['age']), 300)\n",
    "y_smooth = spl(x_smooth)\n",
    "\n",
    "# Plot\n",
    "fig, ax = subplots(figsize=(8,4))\n",
    "ax.scatter(X, y, facecolor='gray', alpha=0.5)\n",
    "ax.plot(X_seq, results.predict(X_seq_t), label='Reg. polinómica grado 4', linewidth=1)\n",
    "ax.plot(x_smooth, y_smooth, label='Spline', linewidth=2)\n",
    "ax.set_xlabel('Age')\n",
    "ax.set_ylabel('Wage')\n",
    "ax.legend(title='', fontsize=12)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qg69RDfECwtv"
   },
   "source": [
    "#### Regresión Local"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "df7dSaJqCwtv"
   },
   "source": [
    "Usamos función [lowess](https://www.statsmodels.org/stable/generated/statsmodels.nonparametric.smoothers_lowess.lowess.html#statsmodels.nonparametric.smoothers_lowess.lowess) de set de funciones no paramétricas de Statsmodels. Esta es una regresión local por Kernels, donde la funcion de Kernels elegida es *tricúbica*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "executionInfo": {
     "elapsed": 1288,
     "status": "ok",
     "timestamp": 1701294792975,
     "user": {
      "displayName": "Victoria Oubina de Castro",
      "userId": "00295192582253170882"
     },
     "user_tz": 180
    },
    "id": "5nTdeFlbCwtv",
    "outputId": "1472c780-958c-44a9-c619-5a96c9797035"
   },
   "outputs": [],
   "source": [
    "import statsmodels as sm\n",
    "\n",
    "X = dataset['age']\n",
    "y = dataset['wage']\n",
    "age_grid = np.linspace(X.min(), X.max(), 100)\n",
    "\n",
    "\n",
    "lowess = sm.nonparametric.smoothers_lowess.lowess\n",
    "\n",
    "spans = [0.1, 0.6]\n",
    "# spans de 0.1 and 0.6. Se consideran 10% o 60% de las observaciones vecinas\n",
    "\n",
    "# Plot\n",
    "fig, ax = subplots(figsize=(8,4))\n",
    "ax.scatter(X, y, facecolor='gray', alpha=0.5)\n",
    "ax.plot(X_seq, results.predict(X_seq_t), label='Reg. polinómica grado 4', linewidth=2)\n",
    "for span in spans:\n",
    "    fitted = lowess(y, X, frac=span, xvals=age_grid)\n",
    "    ax.plot(age_grid, fitted, label='Reg. local {:.1f}'.format(span), linewidth=2)\n",
    "ax.set_xlabel('Age')\n",
    "ax.set_ylabel('Wage')\n",
    "ax.legend(title='', fontsize=12)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NDbw-4vRCwt7"
   },
   "source": [
    "Podemos notar que con span de 0.6 es más suave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "CC408",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
